import json
import re
from typing import Any, Dict, List, Optional, Sequence

import gradio as gr
import numpy as np
import paddle
import torch
from PIL import Image, ImageDraw
from paddleocr import PaddleOCR
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

# --- OCR pipeline ---------------------------------------------------------
# Use a high-capacity OCR model for better accuracy on prescription labels.
OCR_LANGS = ["korean", "en"]
LLM_MODEL_ID = "Qwen/Qwen2.5-1.5B-Instruct"


def _load_ocr():
    use_gpu = torch.cuda.is_available()
    device = "gpu" if use_gpu else "cpu"
    paddle.device.set_device(device)
    return PaddleOCR(
        lang=OCR_LANGS[0],
        use_textline_orientation=True,
        show_log=False,
        text_det_limit_side_len=2048,
        text_det_box_thresh=0.5,
        det_model_dir=None,
        rec_model_dir=None,
    )


ocr_reader = _load_ocr()


def _load_llm():
    device_map = "auto" if torch.cuda.is_available() else None
    dtype = torch.float16 if torch.cuda.is_available() else torch.float32
    model = AutoModelForCausalLM.from_pretrained(
        LLM_MODEL_ID,
        device_map=device_map,
        torch_dtype=dtype,
        trust_remote_code=True,
    )
    if device_map is None:
        model = model.to(torch.device("cpu"))
    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_ID, trust_remote_code=True)
    return model, tokenizer


LLM_MODEL, LLM_TOKENIZER = _load_llm()

# Korean keywords describing time slots on prescription labels.
TIME_KEYWORDS = [
    "ì•„ì¹¨",
    "ì ì‹¬",
    "ì €ë…",
    "ì·¨ì¹¨",
    "ìê¸°",
    "ì‹ì „",
    "ì‹í›„",
    "ì‹ê°„",
    "ê¸°ìƒ",
]

# Very small knowledge base for common Korean OTC medications.
MED_KNOWLEDGE: Sequence[Dict[str, Any]] = [
    {
        "keywords": ["íƒ€ì´ë ˆë†€", "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ", "acetaminophen"],
        "category": "ì§„í†µÂ·í•´ì—´ì œ",
        "what_it_does": "ëª¸ì‚´ì´ë‚˜ ê°ê¸°ë¡œ ì—´ì´ ë‚˜ê±°ë‚˜ ë¨¸ë¦¬ê°€ ì•„í”Œ ë•Œ í†µì¦ê³¼ ì—´ì„ ë‚®ì¶° ì¤ë‹ˆë‹¤.",
        "example": "ì˜ˆ: ìˆ˜í•™ì‹œí—˜ ì¤€ë¹„ë¡œ ê¸´ì¥í–ˆëŠ”ë° ë¨¸ë¦¬ê°€ ì§€ëˆê±°ë¦´ ë•Œ, í•œ ì•Œ ë³µìš©í•˜ë©´ í†µì¦ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.",
        "tip": "ìœ„ì— ë¶€ë‹´ì„ ì¤„ì´ê¸° ìœ„í•´ ê°„ë‹¨í•œ ê°„ì‹ê³¼ í•¨ê»˜ ë¬¼ê³¼ ë³µìš©í•˜ê³ , í•˜ë£¨ ì´ ë³µìš© íšŸìˆ˜(ì¼ë°˜ì ìœ¼ë¡œ 4íšŒ ì´í•˜)ë¥¼ ë„˜ê¸°ì§€ ë§ˆì„¸ìš”.",
    },
    {
        "keywords": ["ì´ë¶€í”„ë¡œíœ", "ë¶€ë£¨íœ", "ibuprofen"],
        "category": "ì§„í†µÂ·ì†Œì—¼ì œ",
        "what_it_does": "ëª¸ì† ì—¼ì¦ì„ ê°€ë¼ì•‰íˆê³  í†µì¦ì„ ì™„í™”í•´ì„œ ê·¼ìœ¡í†µì´ë‚˜ ì¹˜í†µì— ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.",
        "example": "ì˜ˆ: ì²´ìœ¡ ì‹œê°„ì— ë¬´ë¦ì„ ì‚´ì§ ì‚ì—ˆì„ ë•Œ ë¶“ê¸°ì™€ ì•„í””ì„ ì¤„ì—¬ ì¤ë‹ˆë‹¤.",
        "tip": "ì‹í›„ì— ë³µìš©í•˜ë©´ ì† ì“°ë¦¼ì„ ì¤„ì¼ ìˆ˜ ìˆê³ , ë‹¤ë¥¸ ì†Œì—¼ì§„í†µì œì™€ëŠ” ì‹œê°„ ê°„ê²©ì„ ë‘ì„¸ìš”.",
    },
    {
        "keywords": ["ì‹œì˜", "ì„¸í‹°ë¦¬ì§„", "cetirizine", "ì§€ë¥´í…"],
        "category": "ì•Œë ˆë¥´ê¸° ì™„í™”ì œ",
        "what_it_does": "ì½”ê°€ ê°„ì§ˆê±°ë¦¬ê±°ë‚˜ í”¼ë¶€ê°€ ê°€ë ¤ìš¸ ë•Œ ì•Œë ˆë¥´ê¸° ë°˜ì‘ì„ ê°€ë¼ì•‰í˜€ ì¤ë‹ˆë‹¤.",
        "example": "ì˜ˆ: ë´„ì²  ê½ƒê°€ë£¨ ë•Œë¬¸ì— ê¸°ì¹¨ê³¼ ì½§ë¬¼ì´ ë‚˜ì˜¬ ë•Œ ì¦ìƒì„ ì¤„ì—¬ ì¤ë‹ˆë‹¤.",
        "tip": "ì¡¸ë¦´ ìˆ˜ ìˆìœ¼ë‹ˆ ì²« ë³µìš© í›„ì—ëŠ” ìš´ì „ì´ë‚˜ ì§‘ì¤‘ì´ í•„ìš”í•œ í™œë™ì€ í”¼í•˜ì„¸ìš”.",
    },
    {
        "keywords": ["í›¼ìŠ¤íƒˆ", "pancreatin", "ìœ„ì¥", "ì†Œí™”ì œ"],
        "category": "ì†Œí™”ì œ",
        "what_it_does": "ê¸°ë¦„ì§„ ìŒì‹ì„ ë¨¹ê³  ë°°ê°€ ë”ë¶€ë£©í•  ë•Œ ì†Œí™”ë¥¼ ë„ì™€ ì†ì„ í¸í•˜ê²Œ í•´ ì¤ë‹ˆë‹¤.",
        "example": "ì˜ˆ: ì¹˜í‚¨ì„ ë§ì´ ë¨¹ì–´ ì†ì´ ë”ë¶€ë£©í•  ë•Œ ì†ì„ ê°€ë³ê²Œ í•´ ì¤ë‹ˆë‹¤.",
        "tip": "ì‹í›„ì— ë³µìš©í•˜ë©´ íš¨ê³¼ê°€ ì¢‹ìœ¼ë©°, ë³µí†µì´ ê³„ì†ë˜ë©´ ë³‘ì›ì„ ë°©ë¬¸í•˜ì„¸ìš”.",
    },
    {
        "keywords": ["ë¹„íƒ€ë¯¼", "multivitamin", "vitamin"],
        "category": "ì˜ì–‘ì œ",
        "what_it_does": "ëª¸ì— í•„ìš”í•œ ë¹„íƒ€ë¯¼ì„ ì±„ì›Œ í”¼ê³¤í•¨ì„ ì¤„ì´ê³  ë©´ì—­ë ¥ì„ ë•ìŠµë‹ˆë‹¤.",
        "example": "ì˜ˆ: ì‹œí—˜ ì¤€ë¹„ë¡œ ì ì„ ì¤„ì˜€ì„ ë•Œ ëª¸ì´ ì§€ì¹˜ì§€ ì•Šë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.",
        "tip": "í•˜ë£¨ ê¶Œì¥ëŸ‰ì„ ì§€ì¼œ ê¾¸ì¤€íˆ ë³µìš©í•˜ë©´ ë” íš¨ê³¼ì ì´ë©°, ë¬¼ê³¼ í•¨ê»˜ ì‚¼í‚¤ì„¸ìš”.",
    },
]


def _extract_time_slots(text: str) -> List[str]:
    slots = []
    for kw in TIME_KEYWORDS:
        if kw in text:
            slots.append(kw)
    # Also capture explicit times like 08:00 í˜¹ì€ 8ì‹œ
    for match in re.findall(r"(\d{1,2}[:ì‹œ]\d{0,2})", text):
        norm = match.replace("ì‹œ", ":")
        if norm.endswith(":"):
            norm += "00"
        if norm not in slots:
            slots.append(norm)
    return slots


STOPWORDS = {"ìš©ë²•", "ìš©ëŸ‰", "ë³µìš©", "ë°©ë²•", "ì•½", "ì •"}


def _extract_medications(text: str) -> List[Dict[str, Optional[str]]]:
    meds: List[Dict[str, Optional[str]]] = []
    pattern = re.compile(
        r"([ê°€-í£A-Za-z]{2,})[\sÂ·]*(\d+[\./]?\d*\s*(?:mg|mL|ML|ml|ì •|ìº¡ìŠ))?"
    )
    seen: set[str] = set()
    for match in pattern.finditer(text):
        name = match.group(1)
        if name in STOPWORDS or len(name) <= 1:
            continue
        if any(sw in name for sw in STOPWORDS):
            continue
        name_norm = name.strip()
        if name_norm in seen:
            continue
        seen.add(name_norm)
        dose = match.group(2).strip() if match.group(2) else None
        meds.append({"name": name_norm, "dose": dose})
    return meds


def parse_fields(raw: str) -> Dict[str, Any]:
    """Extract drug name and dosage information from OCR text."""
    collapsed = raw.replace("\n", " ")
    collapsed = re.sub(r"\s+", " ", collapsed)

    medications = _extract_medications(collapsed)

    first = medications[0] if medications else {"name": None, "dose": None}
    drug_name = first.get("name")
    dose_per_intake = first.get("dose")

    times_per_day: Optional[int] = None
    times_match = re.search(r"(?:1ì¼|í•˜ë£¨)\s*(\d+)\s*íšŒ", collapsed)
    if times_match:
        times_per_day = int(times_match.group(1))

    time_slots = _extract_time_slots(collapsed)

    return {
        "drug_name": drug_name,
        "dose_per_intake": dose_per_intake,
        "times_per_day": times_per_day,
        "time_slots": time_slots or None,
        "medications": medications,
    }


def ocr_and_parse(image: Image.Image) -> Dict[str, Any]:
    np_img = np.array(image.convert("RGB"))
    ocr_results = ocr_reader.ocr(np_img, cls=True)

    segments: List[Dict[str, Any]] = []
    lines: List[str] = []
    for result in ocr_results:
        if not result:
            continue
        for bbox, (text, confidence) in result:
            cleaned = (text or "").strip()
            if not cleaned:
                continue
            lines.append(cleaned)
            box_serializable = np.asarray(bbox, dtype=float).tolist()
            segments.append({
                "text": cleaned,
                "confidence": float(confidence),
                "bbox": box_serializable,
            })

    raw_text = "\n".join(lines)
    fields = parse_fields(raw_text)

    warnings: List[str] = []
    if not fields["drug_name"]:
        warnings.append("ì•½ ì´ë¦„ ì¸ì‹ì´ ë¶ˆí™•ì‹¤í•©ë‹ˆë‹¤.")
    if not fields["times_per_day"]:
        warnings.append("1ì¼ íšŸìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì˜ˆ: 1ì¼ 3íšŒ).")

    return {
        "raw_text": raw_text,
        "fields": fields,
        "warnings": warnings,
        "segments": segments,
    }


def render_card(fields: Dict[str, Any]) -> Image.Image:
    width, height = 720, 400
    img = Image.new("RGB", (width, height), "white")
    draw = ImageDraw.Draw(img)

    header_text = "ì˜¤ëŠ˜ ë³µìš© ì¼ì •"
    draw.rectangle((0, 0, width, 60), fill=(230, 240, 255))
    draw.text((24, 18), header_text, fill=(0, 0, 0))

    y = 90

    def add_line(label: str, value: Optional[str]):
        nonlocal y
        draw.text((24, y), label, fill=(60, 60, 60))
        display = value if value else "-"
        draw.text((180, y), f": {display}", fill=(0, 0, 0))
        y += 34

    add_line("ì•½ ì´ë¦„", fields.get("drug_name"))
    add_line("1íšŒ ìš©ëŸ‰", fields.get("dose_per_intake"))
    add_line("1ì¼ íšŸìˆ˜", str(fields.get("times_per_day") or ""))

    slots = fields.get("time_slots") or []
    add_line("ì‹œê°„ëŒ€", ", ".join(slots) if slots else None)

    footer = "â€» ì˜ë£Œì§„ ì²˜ë°©ì´ ìš°ì„ ì´ë©°, ë³¸ ì•±ì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤."
    draw.text((24, height - 60), footer, fill=(120, 120, 120))
    return img


def to_csv_row(output: Dict[str, Any]) -> str:
    fields = output["fields"]
    row = [
        fields.get("drug_name") or "",
        fields.get("dose_per_intake") or "",
        str(fields.get("times_per_day") or ""),
        ";".join(fields.get("time_slots") or []),
    ]
    return ",".join(row)


def _match_knowledge(name: str) -> Optional[Dict[str, Any]]:
    lowered = name.lower()
    for info in MED_KNOWLEDGE:
        for kw in info["keywords"]:
            if kw.lower() in lowered or lowered in kw.lower():
                return info
    return None


def build_kb_explanations(output: Dict[str, Any]) -> str:
    meds = output["fields"].get("medications") or []
    if not meds:
        return (
            "### ì•½ ì„¤ëª…\n"
            "- ì•½ ì´ë¦„ì„ ì •í™•íˆ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”. ì‚¬ì§„ì„ ë‹¤ì‹œ ì°ê±°ë‚˜ ì•½ì‚¬ì—ê²Œ ì§ì ‘ í™•ì¸í•´ ì£¼ì„¸ìš”.\n"
            "\n> âš ï¸ ì˜ë£Œì§„ ì²˜ë°©ê³¼ ë³µì•½ ì§€ì‹œê°€ ê°€ì¥ ìš°ì„ ì…ë‹ˆë‹¤."
        )

    lines = ["### ì‰½ê²Œ ì•Œì•„ë³´ëŠ” ì•½ ì„¤ëª…"]
    for med in meds:
        name = med.get("name") or "ì´ë¦„ ë¯¸í™•ì¸"
        info = _match_knowledge(name) if name else None
        dose = med.get("dose")
        if info:
            lines.append(
                f"- **{name}** ({info['category']})"
            )
            if dose:
                lines.append(f"  - ì•½ ë´‰íˆ¬ì— ì íŒ ìš©ëŸ‰: `{dose}`")
            lines.append(f"  - í•˜ëŠ” ì¼: {info['what_it_does']}")
            lines.append(f"  - ì¤‘í•™ìƒ ì˜ˆì‹œ: {info['example']}")
            lines.append(f"  - ë³µìš© íŒ: {info['tip']}")
        else:
            lines.append(f"- **{name}**")
            if dose:
                lines.append(f"  - ì•½ ë´‰íˆ¬ ìš©ëŸ‰: `{dose}`")
            lines.append(
                "  - ì•„ì§ ë°ì´í„°ê°€ ì—†ì–´ìš”. ì•½ ì´ë¦„ì„ ë‹¤ì‹œ í™•ì¸í•˜ê±°ë‚˜ ì•½ì‚¬ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”."
            )

    lines.append("\n> âš ï¸ ì‹¤ì œ ë³µì•½ì€ ì˜ì‚¬Â·ì•½ì‚¬ì˜ ì§€ì‹œì— ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”.")
    return "\n".join(lines)


def generate_llm_explanations(output: Dict[str, Any]) -> str:
    meds = output["fields"].get("medications") or []
    if not meds:
        return (
            "ì•½ ì´ë¦„ì„ ì œëŒ€ë¡œ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”. ì‚¬ì§„ì„ ë‹¤ì‹œ ì°ê±°ë‚˜ ì•½ì‚¬ì—ê²Œ ì§ì ‘ í™•ì¸í•´ ì£¼ì„¸ìš”."
        )

    med_lines = []
    for idx, med in enumerate(meds, 1):
        name = med.get("name") or "ì´ë¦„ ë¯¸í™•ì¸"
        dose = med.get("dose") or "ìš©ëŸ‰ ì •ë³´ ì—†ìŒ"
        med_lines.append(f"{idx}. {name} â€” {dose}")

    context = "\n".join(med_lines)
    raw_text = output.get("raw_text", "")

    system_prompt = (
        "ë‹¹ì‹ ì€ ì•½ì‚¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ì–´ë ¤ìš´ ì˜í•™ ìš©ì–´ë¥¼ ì“°ì§€ ë§ê³ , ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ë§íˆ¬ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”."
    )
    user_prompt = (
        "ë‹¤ìŒì€ ì•½ë´‰íˆ¬ì—ì„œ OCRë¡œ ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•½ ì´ë¦„ê³¼ ë³µìš© ì§€ì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° ì•½ì˜ ì •ë³´ë¥¼ ì•„ì£¼ ì‰½ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n"
        "ìš”êµ¬ ì‚¬í•­:\n"
        "1. ê° ì•½ë§ˆë‹¤ ì•„ë˜ í•­ëª©ì„ bullet í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n"
        "   - ì•½ ì´ë¦„: (ê°€ëŠ¥í•˜ë©´ í•œê¸€/ì˜ë¬¸ ë³‘ê¸°)\n"
        "   - ì–´ë–¤ ì•½ì¸ì§€ í•œ ì¤„ ì„¤ëª…\n"
        "   - ë³µìš© ì˜ˆì‹œ: ì–¸ì œ, ì–´ë–¤ ìƒí™©ì—ì„œ ë³µìš©í•˜ë©´ ì¢‹ì€ì§€ ì˜ˆì‹œ\n"
        "   - ë³µìš© ë°©ë²• ì˜ˆì‹œ: 1íšŒ ìš©ëŸ‰/í•˜ë£¨ íšŸìˆ˜ê°€ ìˆë‹¤ë©´ ì–¸ê¸‰\n"
        "   - ë¶€ì‘ìš© ë˜ëŠ” ì£¼ì˜ì‚¬í•­: í”í•œ ë¶€ì‘ìš©, í”¼í•´ì•¼ í•  í–‰ë™\n"
        "2. ì–´ë ¤ìš´ ì˜í•™ ìš©ì–´ëŠ” í”¼í•˜ê³ , ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ë§íˆ¬ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n"
        "3. ì•½ ì´ë¦„ì„ í™•ì‹¤íˆ ëª¨ë¥´ë©´ â€˜ì´ë¦„ ë¯¸í™•ì¸â€™ì´ë¼ê³  ì“°ê³ , ì•½ì‚¬ì—ê²Œ í™•ì¸í•˜ë¼ê³  ì•ˆë‚´í•©ë‹ˆë‹¤.\n"
        "4. ë§ˆì§€ë§‰ ë¬¸ë‹¨ì— ë°˜ë“œì‹œ â€˜ì‹¤ì œ ë³µì•½ì€ ì˜ì‚¬Â·ì•½ì‚¬ì˜ ì§€ì‹œë¥¼ ë”°ë¥´ì„¸ìš”â€™ ë¬¸ì¥ì„ í¬í•¨í•˜ì„¸ìš”.\n"
        f"\nì•½ ëª©ë¡(ì¶”ì¶œ ìš”ì•½):\n{context}\n\nOCR ì›ë¬¸ ì „ì²´:\n{raw_text}\n"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    input_ids = LLM_TOKENIZER.apply_chat_template(
        messages,
        add_generation_prompt=True,
        return_tensors="pt",
    )
    input_ids = input_ids.to(LLM_MODEL.device)

    with torch.no_grad():
        output_ids = LLM_MODEL.generate(
            input_ids,
            max_new_tokens=480,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            eos_token_id=LLM_TOKENIZER.eos_token_id,
        )

    generated_ids = output_ids[0][input_ids.shape[1]:]
    text = LLM_TOKENIZER.decode(generated_ids, skip_special_tokens=True).strip()
    return text


def build_explanations(output: Dict[str, Any]) -> str:
    try:
        llm_text = generate_llm_explanations(output)
        if llm_text:
            return llm_text
    except Exception as err:  # pragma: no cover - safe fallback
        print(f"[WARN] LLM generation failed: {err}", flush=True)
    return build_kb_explanations(output)


def format_warnings(warnings: List[str]) -> str:
    if not warnings:
        return "âœ… ì¸ì‹ëœ ì •ë³´ê°€ ì¶©ë¶„í•´ìš”. ë³µì•½ ì‹œê°„ë§Œ ì˜ ì§€ì¼œ ì£¼ì„¸ìš”."
    lines = ["### í™•ì¸í•´ ì£¼ì„¸ìš”"]
    for warn in warnings:
        lines.append(f"- {warn}")
    lines.append("\n> ì˜ë£Œì§„ì˜ ì§€ì‹œê°€ ê°€ì¥ ì •í™•í•©ë‹ˆë‹¤.")
    return "\n".join(lines)


def run_pipeline(image: Optional[Image.Image]):
    if image is None:
        return (
            "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.",
            None,
            None,
            "ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.",
            "ğŸ“· ì•½ ë´‰íˆ¬ ì‚¬ì§„ì„ ì˜¬ë¦¬ë©´ ì¸ì‹ì´ ì‹œì‘ë¼ìš”.",
            "",
        )

    output = ocr_and_parse(image)
    card = render_card(output["fields"])
    csv_row = to_csv_row(output)
    json_text = json.dumps(output, ensure_ascii=False, indent=2)
    explanations = build_explanations(output)
    warnings_md = format_warnings(output.get("warnings", []))
    return json_text, card, csv_row, explanations, warnings_md, output.get("raw_text", "")


CUSTOM_CSS = """
body {background: radial-gradient(circle at top left, #f5f0ff 0%, #fff7ec 60%, #ffffff 100%);}
.gradio-container {max-width: 1180px !important; margin: auto; font-family: 'Noto Sans KR', sans-serif;}
.hero {
  background: linear-gradient(120deg, rgba(123, 97, 255, 0.12), rgba(255, 207, 117, 0.18));
  border-radius: 28px;
  padding: 36px 44px;
  box-shadow: 0 20px 40px rgba(66, 46, 138, 0.08);
  margin-bottom: 32px;
}
.hero h1 {font-size: 2.4rem; font-weight: 700; color: #1f1c3b; margin-bottom: 12px;}
.hero p {color: #514c7b; font-size: 1.05rem; line-height: 1.6; max-width: 640px;}
.glass-panel {background: rgba(255, 255, 255, 0.72); backdrop-filter: blur(18px); border-radius: 26px; padding: 28px; box-shadow: 0 12px 32px rgba(80, 60, 160, 0.12);}
.panel-title {font-weight: 700; font-size: 1.2rem; margin-bottom: 18px; color: #2f2355;}
.primary-btn button {background: linear-gradient(120deg, #7c62ff, #ffa74d); border: none; color: white; font-weight: 600; border-radius: 999px; padding: 12px 22px; box-shadow: 0 12px 24px rgba(124, 98, 255, 0.25);} 
.primary-btn button:hover {opacity: 0.95; transform: translateY(-1px);}
.output-card {background: rgba(255, 255, 255, 0.88); border-radius: 22px; padding: 24px; box-shadow: inset 0 0 0 1px rgba(124, 98, 255, 0.08), 0 14px 30px rgba(49, 32, 114, 0.12);}
.notice {background: rgba(255, 247, 226, 0.9); border-radius: 18px; padding: 18px; color: #7a4b00; box-shadow: inset 0 0 0 1px rgba(255, 193, 96, 0.3);}
.csv-box textarea {font-family: 'JetBrains Mono', monospace;}
.gr-image {border-radius: 20px !important; box-shadow: 0 10px 20px rgba(60, 40, 120, 0.15);}
.accordion {border-radius: 20px !important;}
"""

HERO_HTML = """
<div class="hero">
  <h1>MedCard-KR Â· ì•½ë´‰íˆ¬ í•œ ì»·ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë³µìš© ì•ˆë‚´</h1>
  <p>ì‚¬ì§„ ì† ì•½ ì´ë¦„ì„ OCRë¡œ ì½ì–´ ë“¤ì´ê³ , Qwen LLMì´ ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ë§íˆ¬ë¡œ ì•½ì„ ì„¤ëª…í•´ ë“œë¦½ë‹ˆë‹¤.
     ë³µìš© ì¼ì • ì¹´ë“œì™€ CSVê¹Œì§€ í•œ ë²ˆì— ë°›ì•„ ë³´ì„¸ìš”.</p>
</div>
"""


with gr.Blocks(theme=gr.themes.Soft(), css=CUSTOM_CSS) as demo:
    gr.HTML(HERO_HTML)
    with gr.Row():
        with gr.Column(scale=4, elem_classes=["glass-panel"]):
            gr.Markdown("### 1. ì•½ ë´‰íˆ¬ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
            img_in = gr.Image(type="pil", label="ì•½ ë´‰íˆ¬/ë¼ë²¨ ì‚¬ì§„", height=360)
            warn_md = gr.Markdown("ğŸ“· ì•½ ë´‰íˆ¬ ì‚¬ì§„ì„ ì˜¬ë¦¬ë©´ ì¸ì‹ì´ ì‹œì‘ë¼ìš”.", elem_classes=["notice"])
            btn = gr.Button("ì¸ì‹ & ì„¤ëª… ìƒì„±", elem_classes=["primary-btn"])
        with gr.Column(scale=6, elem_classes=["glass-panel"]):
            gr.Markdown("### 2. ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”")
            explain_md = gr.Markdown("ì—¬ê¸°ì— ì•½ ì„¤ëª…ì´ í‘œì‹œë©ë‹ˆë‹¤.", elem_classes=["output-card"])
            raw_box = gr.Textbox(label="OCR ì›ë¬¸ í…ìŠ¤íŠ¸", lines=5, interactive=False)
            card_out = gr.Image(type="pil", label="ì¼ì • ì¹´ë“œ(ë¯¸ë¦¬ë³´ê¸°)")
            csv_box = gr.Textbox(label="CSV(ì•½ëª…,1íšŒìš©ëŸ‰,1ì¼íšŸìˆ˜,ì‹œê°„ëŒ€)", lines=2, elem_classes=["csv-box"])
            with gr.Accordion("ì„¸ë¶€ JSON ê²°ê³¼", open=False, elem_classes=["accordion"]):
                json_out = gr.Code(label="ì¸ì‹ ê²°ê³¼(JSON)")

    btn.click(
        run_pipeline,
        inputs=img_in,
        outputs=[json_out, card_out, csv_box, explain_md, warn_md, raw_box],
    )

    gr.Markdown(
        """
        > â„¹ï¸ **ì£¼ì˜**: ì´ ì„œë¹„ìŠ¤ëŠ” ì°¸ê³ ìš© ë„êµ¬ì´ë©°, ì‹¤ì œ ë³µì•½ì€ ë°˜ë“œì‹œ ì˜ì‚¬Â·ì•½ì‚¬ì˜ ì§€ì‹œì— ë”°ë¼ ì£¼ì„¸ìš”.
        """
    )


if __name__ == "__main__":
    demo.queue().launch()
